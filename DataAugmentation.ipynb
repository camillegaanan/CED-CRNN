{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#DATA AUGMENTATION\r\n",
    "\r\n",
    "# Importing necessary functions\r\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\r\n",
    "import os\r\n",
    "\r\n",
    "def augment_images(image_path, filename):\r\n",
    "\t\t# Loading a sample image\r\n",
    "\t\timg = load_img(image_path)\r\n",
    "\t\t# Converting the input sample image to an array\r\n",
    "\t\tx = img_to_array(img)\r\n",
    "\t\t# Reshaping the input image\r\n",
    "\t\tx = x.reshape((1, ) + x.shape)\r\n",
    "\r\n",
    "\t\t# Generating and saving 5 augmented samples\r\n",
    "\t\t# using the above defined parameters.\r\n",
    "\t\ti = 0\r\n",
    "\t\tfor batch in datagen.flow(x, batch_size = 16,\r\n",
    "\t\t\t\t\t\t\t\tsave_to_dir ='C:/Users/Camille/Downloads/NEW PATH 2', #Camille\r\n",
    "\t\t\t\t\t\t\t\t# save_to_dir ='D:/Program Files/NEW CROPPED LABELED RESIZED PRES PICS', #Ash\r\n",
    "\t\t\t\t\t\t\t\tsave_prefix =filename+'_'+str(i), save_format ='jpg'):\r\n",
    "\t\t\ti += 1\r\n",
    "\t\t\tif i > 5:\r\n",
    "\t\t\t\tbreak\r\n",
    "\r\n",
    "# Initialising the ImageDataGenerator class.\r\n",
    "# We will pass in the augmentation parameters in the constructor.\r\n",
    "datagen = ImageDataGenerator(\r\n",
    "\t\trotation_range = 5,\r\n",
    "\t\tshear_range = 1,\r\n",
    "\t\tzoom_range = 0.2,\r\n",
    "\t\trescale=1)\r\n",
    "\r\n",
    "input_path = 'C:/Users/Camille/Downloads/CROPPED LABELED RESIZED PRES PICS 2' #Camille\r\n",
    "# input_path = 'D:\\Program Files\\CROPPED LABELED RESIZED PRES PICS' #Ash\r\n",
    "for filename in os.listdir(input_path):\r\n",
    "\tif filename.endswith(\".jpg\"):\r\n",
    "\t\timage_path = os.path.join(input_path, filename)\r\n",
    "\t\taugment_images(image_path, filename[:-4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# # Creating Train / Val / Test folders (One time use)\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import shutil\r\n",
    "import random\r\n",
    "root_dir = 'C:/Users/Camille/Downloads/splitted data 2/' #Camille\r\n",
    "# root_dir = 'D:/Program Files/SPLIT NEW CROPPED LABELED RESIZED PRES PICS/' #Ash\r\n",
    "\r\n",
    "\r\n",
    "val_ratio = 0\r\n",
    "test_ratio = 0.3\r\n",
    "\r\n",
    "os.makedirs(root_dir +'train/')\r\n",
    "os.makedirs(root_dir +'test/')\r\n",
    "\r\n",
    "# Creating partitions of the data after shuffeling\r\n",
    "src = 'C:/Users/Camille/Downloads/NEW PATH 2' # Folder to copy images from --Camille\r\n",
    "# src = 'D:/Program Files/NEW CROPPED LABELED RESIZED PRES PICS' #Ash\r\n",
    "\r\n",
    "\r\n",
    "allFileNames = os.listdir(src)\r\n",
    "np.random.shuffle(allFileNames)\r\n",
    "train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\r\n",
    "                                                          [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), \r\n",
    "                                                           int(len(allFileNames)* (1 - test_ratio))])\r\n",
    "\r\n",
    "\r\n",
    "train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\r\n",
    "test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\r\n",
    "\r\n",
    "print('Total images: ', len(allFileNames))\r\n",
    "print('Training: ', len(train_FileNames))\r\n",
    "#print('Validation: ', len(val_FileNames))\r\n",
    "print('Testing: ', len(test_FileNames))\r\n",
    "\r\n",
    "# Copy-pasting images\r\n",
    "for name in train_FileNames:\r\n",
    "    shutil.copy(name, root_dir +'train/' )\r\n",
    "\r\n",
    "#for name in val_FileNames:\r\n",
    " #   shutil.copy(name, root_dir +'val/' + cls)\r\n",
    "\r\n",
    "for name in test_FileNames:\r\n",
    "    shutil.copy(name, root_dir +'test/' )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total images:  288\n",
      "Training:  201\n",
      "Testing:  87\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#BINARIZATION\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from skimage.filters import threshold_otsu\r\n",
    "\r\n",
    "def binary(image):\r\n",
    "    (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\r\n",
    "    thresh = 127\r\n",
    "    im_bw = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)[1]\r\n",
    "    return im_bw"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#NOISE REMOVAL\r\n",
    "import bm3d\r\n",
    "def noise(bw):\r\n",
    "    # den = bm3d.bm3d(bw, sigma_psd=30/255, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING)\r\n",
    "    den = cv2.fastNlMeansDenoising(bw, None, 10, 7, 15)\r\n",
    "    return den"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#CED\r\n",
    "from scipy import signal\r\n",
    "\r\n",
    "def ced(image):\r\n",
    "    m1 = np.array([[5, 5, 5],[-3,0,-3],[-3,-3,-3]])\r\n",
    "    m8 = np.array([[-3, 5,5],[-3,0,5],[-3,-3,-3]])\r\n",
    "    m7 = np.array([[-3,-3,5],[-3,0,5],[-3,-3,5]])\r\n",
    "    m6 = np.array([[-3,-3,-3],[-3,0,5],[-3,5,5]])\r\n",
    "    m5 = np.array([[-3, -3, -3],[-3,0,-3],[5,5,5]])\r\n",
    "    m4 = np.array([[-3, -3, -3],[5,0,-3],[5,5,-3]])\r\n",
    "    m3 = np.array([[5, -3, -3],[5,0,-3],[5,-3,-3]])\r\n",
    "    m2 = np.array([[5, 5, -3],[5,0,-3],[-3,-3,-3]])\r\n",
    "    list_m = [m1,m2,m3,m4,m5,m6,m7,m8]\r\n",
    "\r\n",
    "    list_e = []\r\n",
    "    count = 1\r\n",
    "    \r\n",
    "    for m in list_m:\r\n",
    "        imgk = signal.convolve2d(image, m,boundary='symm')\r\n",
    "        list_e.append(np.abs(imgk))\r\n",
    "        out = imgk.astype(np.uint8)\r\n",
    "        count += 1\r\n",
    "    #Seeking maximum\r\n",
    "    count\r\n",
    "    e = list_e[0]\r\n",
    "    for i in range(len(list_e)):\r\n",
    "        e = e*(e>=list_e[i]) + list_e[i]*(e<list_e[i])\r\n",
    "        \r\n",
    "    e[e>255] = 255\r\n",
    "    e=e.astype(np.uint8)\r\n",
    "    return e"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from skimage.morphology import skeletonize\r\n",
    "from skimage import data\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from skimage.util import invert\r\n",
    "\r\n",
    "def skeleton(image):\r\n",
    "    return cv2.ximgproc.thinning(image)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#PREPROCESSING IMAGES\r\n",
    "import time\r\n",
    "import matplotlib.image as imgsave\r\n",
    "# import pandas as pd\r\n",
    "filename = 'C:/Users/Camille/Downloads/splitted data 2/train/'\r\n",
    "filename2 = 'C:/Users/Camille/Downloads/splitted data 2/test/'\r\n",
    "# filename = 'D:/Program Files/SPLIT NEW CROPPED LABELED RESIZED PRES PICS/train/' #Ash\r\n",
    "# filename2 = 'D:/Program Files/SPLIT NEW CROPPED LABELED RESIZED PRES PICS/test/' #Ash\r\n",
    "\r\n",
    "\r\n",
    "def preprocess(train_dir):\r\n",
    "    start_time = time.time()\r\n",
    "    list_images = []\r\n",
    "    for filename in os.listdir(train_dir):\r\n",
    "        image = cv2.imread(os.path.join(train_dir, filename),0)\r\n",
    "        img2 = binary(image)\r\n",
    "        img3 = noise(img2)\r\n",
    "        imgg = cv2.blur(img3,(3,3))\r\n",
    "        img4 = ced(imgg)\r\n",
    "        img5 = skeleton(img4)\r\n",
    "        # img5 = tf.convert_to_tensor(img5)\r\n",
    "        list_images.append(img5)\r\n",
    "    print(\"--- %s seconds --- skeleton image\" % (time.time() - start_time))\r\n",
    "    list_images = np.array(list_images, np.int64)\r\n",
    "    return list_images\r\n",
    "\r\n",
    "list_train_images = preprocess(filename)\r\n",
    "list_test_images = preprocess(filename2)\r\n",
    "print(list_train_images)\r\n",
    "print(list_test_images)\r\n",
    "\r\n",
    "# filepath='C:/Users/Camille/Downloads/pagod na ko/'\r\n",
    "\r\n",
    "# image = cv2.imread('C:/Users/Camille/Downloads/splitted data/train/Hydroxyzine_0_8889.jpg',0)\r\n",
    "\r\n",
    "# img = binary(image)\r\n",
    "# img2 = noise(img)\r\n",
    "\r\n",
    "# img3 = cv2.blur(img2, ksize=(3,3))\r\n",
    "\r\n",
    "# img4 = ced(img3)\r\n",
    "# img5 = skeleton(img4)\r\n",
    "\r\n",
    "# cv2.imwrite(os.path.join(filepath,\"1grey.jpg\"), image)  \r\n",
    "# cv2.imwrite(os.path.join(filepath,\"2binary.jpg\"), img)  \r\n",
    "# cv2.imwrite(os.path.join(filepath,\"3noise.jpg\"), img2)  \r\n",
    "# cv2.imwrite(os.path.join(filepath,\"4blur.jpg\"), img3)  \r\n",
    "# cv2.imwrite(os.path.join(filepath,\"5ced.jpg\"), img4) \r\n",
    "# cv2.imwrite(os.path.join(filepath,\"6skeleton.jpg\"), img5) \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- 59.336859941482544 seconds --- skeleton image\n",
      "--- 24.08628249168396 seconds --- skeleton image\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import tensorflow as tf\r\n",
    "\r\n",
    "# from tensorflow.keras import datasets, layers, models\r\n",
    "# import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\n",
    "\r\n",
    "# # print(train_images)\r\n",
    "# image = cv2.imread(os.path.join(filepath,\"6skeleton.jpg\"))\r\n",
    "# image2 = cv2.imread(os.path.join(filepath,\"6skeleton.jpg\"))\r\n",
    "# list1 = []\r\n",
    "# list1.append(image)\r\n",
    "# list1.append(image2)\r\n",
    "# list2 = np.array(list1, np.int32)\r\n",
    "# print(list2)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#CNN ASH\r\n",
    "import os\r\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n",
    "\r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import string\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, LSTM\r\n",
    "# from tensorflow.compat.v1.keras.layers import CuDNNLSTM\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import *\r\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
    "from tqdm import tqdm\r\n",
    "from collections import Counter\r\n",
    "from PIL import Image\r\n",
    "from itertools import groupby\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# image_paths = []\r\n",
    "image_texts = []\r\n",
    "from pathlib import Path\r\n",
    "# data_folder = \"D:/Program Files/SPLIT NEW CROPPED LABELED RESIZED PRES PICS/train\" #Ash\r\n",
    "data_folder = 'C:/Users/Camille/Downloads/splitted data 2/train'\r\n",
    "data_dir = Path(\"C:/Users/Camille/Downloads/splitted data 2/train\")\r\n",
    "image_paths = sorted(list(map(str, list(data_dir.glob(\"*.jpg\")))))\r\n",
    "print(len(image_paths))\r\n",
    "for filename in os.listdir(data_dir):\r\n",
    "    # image_paths.append(data_folder + \"/\" + filename)\r\n",
    "    # image_texts.append(filename.split(\"/\")[0])\r\n",
    "    if filename.find(\"Azathioprine\") != -1:\r\n",
    "        # image_texts.append(\"Azathioprine: 3-5 mg/kg Per os OD\")\r\n",
    "        image_texts.append(\"Azathioprine 3-5 mg kg Per os OD\")\r\n",
    "    elif filename.find(\"Ceftriaxone\") != -1:\r\n",
    "        # image_texts.append(\"Ceftriaxone: 2 g IV q24h\")\r\n",
    "        image_texts.append(\"Ceftriaxone 2 g IV q24h\")\r\n",
    "    elif filename.find(\"Chlorpromazine\") != -1:\r\n",
    "        # image_texts.append(\"Chlorpromazine: 10-25 mg Per os three times a day\")\r\n",
    "        image_texts.append(\"Chlorpromazine 10 25 mg Per os three times a day\")\r\n",
    "    elif filename.find(\"Dobutamine\") != -1:\r\n",
    "        # image_texts.append(\"Dobutamine: 2.5-15 mcg/kg/min\")\r\n",
    "        image_texts.append(\"Dobutamine 2 5 15 mcg kg min\")\r\n",
    "    elif filename.find(\"Hydroxyzine\") != -1:\r\n",
    "        # image_texts.append(\"Hydroxyzine: 50-100 mg by IJ qds\")\r\n",
    "        image_texts.append(\"Hydroxyzine 50 100 mg by IJ qds\")\r\n",
    "    elif filename.find(\"Lorazepam\") != -1:\r\n",
    "        # image_texts.append(\"Lorazepam: 1 mg Per os 2 times a day\")\r\n",
    "        image_texts.append(\"Lorazepam 1 mg Per os 2 times a day\")\r\n",
    "    elif filename.find(\"Metronidazole\") != -1:\r\n",
    "        # image_texts.append(\"Metronidazole: 7.5 mg/kg Per os q6hr\")\r\n",
    "        image_texts.append(\"Metronidazole 7 5 mg kg Per os q6hr\")\r\n",
    "    elif filename.find(\"Prednisolone\") != -1:\r\n",
    "        # image_texts.append(\"Prednisolone: 5-60 mg per day qds\")\r\n",
    "        image_texts.append(\"Prednisolone 5 60 mg per day qds\")\r\n",
    "    elif filename.find(\"Quinine\") != -1:\r\n",
    "        # image_texts.append(\"Quinine: 648 mg Per os every 8 hours for 7 days\")\r\n",
    "        image_texts.append(\"Quinine 648 mg Per os every 8 hours for 7 days\")\r\n",
    "    elif filename.find(\"Risperidone\") != -1:\r\n",
    "        # image_texts.append(\"Risperidone: 2 mg orally i/d\")\r\n",
    "        image_texts.append(\"Risperidone 2 mg orally i d\")\r\n",
    "    elif filename.find(\"Rituximab\") != -1:\r\n",
    "        # image_texts.append(\"Rituximab: 375 mg/m2 IV once weekly\")\r\n",
    "        image_texts.append(\"Rituximab 375 mg m2 IV once weekly\")\r\n",
    "    else:\r\n",
    "        # image_texts.append(\"Tramadol: 50-100 mg as needed every 4 to 6 hours\")\r\n",
    "        image_texts.append(\"Tramadol 50100 mg as needed every 4 to 6 hours\")\r\n",
    "print(type(image_paths))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "201\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "char_list = set(['0','1','2','3','4','5','6','7','8',':','A','C','D','H','I','J','L','M','O','P','Q','R','T','V','a','b','c','d','e','f','g','h','i','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' '])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "max_label_len = 49"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# def split_data(images, labels, train_size=0.9, shuffle=True):\r\n",
    "#     # 1. Get the total size of the dataset\r\n",
    "#     size = len(images)\r\n",
    "#     # 2. Make an indices array and shuffle it, if required\r\n",
    "#     indices = np.arange(size)\r\n",
    "#     if shuffle:\r\n",
    "#         np.random.shuffle(indices)\r\n",
    "#     # 3. Get the size of training samples\r\n",
    "#     train_samples = int(size * train_size)\r\n",
    "#     # 4. Split data into training and validation sets\r\n",
    "#     x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\r\n",
    "#     x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\r\n",
    "#     return x_train, x_valid, y_train, y_valid\r\n",
    "\r\n",
    "# # print(image_path)\r\n",
    "# # Splitting data into training and validation sets\r\n",
    "# train_image_paths, train_image_texts, val_image_paths, val_image_texts = split_data(np.array(image_paths), np.array(image_texts))\r\n",
    "# # print(type(train_image_paths))\r\n",
    "\r\n",
    "def split_data(images, labels, train_size=0.9, shuffle=True):\r\n",
    "    # 1. Get the total size of the dataset\r\n",
    "    size = len(images)\r\n",
    "    # 2. Make an indices array and shuffle it, if required\r\n",
    "    indices = np.arange(size)\r\n",
    "    if shuffle:\r\n",
    "        np.random.shuffle(indices)\r\n",
    "    # 3. Get the size of training samples\r\n",
    "    train_samples = int(size * train_size)\r\n",
    "    # 4. Split data into training and validation sets\r\n",
    "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\r\n",
    "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\r\n",
    "    return x_train, x_valid, y_train, y_valid\r\n",
    "\r\n",
    "\r\n",
    "# Splitting data into training and validation sets\r\n",
    "train_image_paths, val_image_paths, train_image_texts, val_image_texts = split_data(np.array(image_paths), np.array(image_texts))\r\n",
    "print(len(train_image_paths))\r\n",
    "print(len(train_image_texts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "180\n",
      "180\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "def encode_to_labels(txt):\r\n",
    "    # encoding each output word into digits\r\n",
    "    dig_lst = []\r\n",
    "    \r\n",
    "    for index, char in enumerate(txt):\r\n",
    "        try:\r\n",
    "            dig_lst.append(char_list.index(char))\r\n",
    "        except:\r\n",
    "            print(char)\r\n",
    "    \r\n",
    "    return pad_sequences([dig_lst], maxlen=max_label_len, padding='post', value=len(char_list))[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "source": [
    "# padded_image_texts = list(map(encode_to_labels, image_texts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "source": [
    "# train_image_paths = image_paths[ : int(len(image_paths) * 0.90)]\r\n",
    "\r\n",
    "# train_image_texts = padded_image_texts[ : int(len(image_texts) * 0.90)]\r\n",
    "# print(train_image_texts)\r\n",
    "# val_image_paths = image_paths[int(len(image_paths) * 0.90) : ]\r\n",
    "# val_image_texts = padded_image_texts[int(len(image_texts) * 0.90) : ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Mapping characters to integers\r\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\r\n",
    "    vocabulary=list(char_list), num_oov_indices=0, mask_token=None\r\n",
    ")\r\n",
    "def process_single_sample(img_path, label):\r\n",
    "\r\n",
    "    # 1. Read image\r\n",
    "    img = tf.io.read_file(img_path)\r\n",
    "\r\n",
    "    # 2. Decode and convert to grayscale\r\n",
    "    img = tf.io.decode_png(img, channels=1)\r\n",
    "    # 3. Convert to float32 in [0, 1] range\r\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\r\n",
    "\r\n",
    "    # 4. Resize to the desired size\r\n",
    "    img = tf.image.resize(img, [64, 64])\r\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\r\n",
    "    # 6. Map the characters in label to numbers\r\n",
    "    #\r\n",
    "    label = char_to_num(tf.strings.unicode_split(str(label), 'UTF-8'))\r\n",
    "    print(label)\r\n",
    "\r\n",
    "    return {\"image\": img, \"label\": label}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "batch_size = 10\r\n",
    "print(len(train_image_paths))\r\n",
    "print(len(train_image_texts))\r\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_texts))\r\n",
    "\r\n",
    "train_dataset = (\r\n",
    "    train_dataset.map(\r\n",
    "        process_single_sample, num_parallel_calls=tf.data.AUTOTUNE\r\n",
    "    )\r\n",
    "    .batch(batch_size)\r\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\r\n",
    ")\r\n",
    "\r\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_image_texts))\r\n",
    "validation_dataset = (\r\n",
    "    validation_dataset.map(\r\n",
    "        process_single_sample, num_parallel_calls=tf.data.AUTOTUNE\r\n",
    "    )\r\n",
    "    .batch(batch_size)\r\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "180\n",
      "180\n",
      "Tensor(\"string_lookup_5/None_lookup_table_find/LookupTableFindV2:0\", shape=(42,), dtype=int64, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "Tensor(\"string_lookup_5/None_lookup_table_find/LookupTableFindV2:0\", shape=(42,), dtype=int64, device=/job:localhost/replica:0/task:0/device:CPU:0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "class CTCLayer(layers.Layer):\r\n",
    "\r\n",
    "    def __init__(self, name=None):\r\n",
    "        \r\n",
    "        super().__init__(name=name)        \r\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\r\n",
    "\r\n",
    "    def call(self, y_true, y_pred):\r\n",
    "        # Compute the training-time loss value and add it\r\n",
    "        # to the layer using `self.add_loss()`.\r\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\r\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\r\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\r\n",
    "\r\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\r\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\r\n",
    "\r\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\r\n",
    "        self.add_loss(loss)\r\n",
    "\r\n",
    "        # At test time, just return the computed predictions\r\n",
    "        return y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def ctc_decoder(predictions):\r\n",
    "    '''\r\n",
    "    input: given batch of predictions from text rec model\r\n",
    "    output: return lists of raw extracted text\r\n",
    "\r\n",
    "    '''\r\n",
    "    text_list = []\r\n",
    "    \r\n",
    "    pred_indcies = np.argmax(predictions, axis=2)\r\n",
    "    \r\n",
    "    for i in range(pred_indcies.shape[0]):\r\n",
    "        ans = \"\"\r\n",
    "        \r\n",
    "        ## merge repeats\r\n",
    "        merged_list = [k for k,_ in groupby(pred_indcies[i])]\r\n",
    "        \r\n",
    "        ## remove blanks\r\n",
    "        for p in merged_list:\r\n",
    "            if p != len(char_list):\r\n",
    "                ans += char_list[int(p)]\r\n",
    "        \r\n",
    "        text_list.append(ans)\r\n",
    "        \r\n",
    "    return text_list\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "source": [
    "# figures_list = []\r\n",
    "\r\n",
    "# class PlotPredictions(tf.keras.callbacks.Callback):\r\n",
    "\r\n",
    "#     def __init__(self, frequency=1):\r\n",
    "#         self.frequency = frequency\r\n",
    "#         super(PlotPredictions, self).__init__()\r\n",
    "\r\n",
    "#         batch = validation_dataset.take(1)\r\n",
    "#         self.batch_images = list(batch.as_numpy_iterator())[0][\"image\"]\r\n",
    "#         self.batch_labels = list(batch.as_numpy_iterator())[0][\"label\"]\r\n",
    "\r\n",
    "#     def plot_predictions(self, epoch):\r\n",
    "\r\n",
    "#         prediction_model = keras.models.Model(\r\n",
    "#             self.model.get_layer(name=\"image\").input, \r\n",
    "#             self.model.get_layer(name=\"dense\").output\r\n",
    "#         )\r\n",
    "        \r\n",
    "#         preds = prediction_model.predict(self.batch_images)\r\n",
    "#         pred_texts = ctc_decoder(preds)\r\n",
    "\r\n",
    "#         orig_texts = []\r\n",
    "\r\n",
    "#         for label in self.batch_labels:\r\n",
    "#             orig_texts.append(\"\".join([char_list[int(char_ind)] for char_ind in label if not(char_ind == len(char_list))]))\r\n",
    "\r\n",
    "#         fig , ax = plt.subplots(4, 4, figsize=(15, 5))\r\n",
    "#         fig.suptitle('Epoch: '+str(epoch), weight='bold', size=14)\r\n",
    "\r\n",
    "#         for i in range(16):\r\n",
    "\r\n",
    "#             img = (self.batch_images[i, :, :, 0] * 255).astype(np.uint8)\r\n",
    "#             title = f\"Prediction: {pred_texts[i]}\"\r\n",
    "#             ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\r\n",
    "#             ax[i // 4, i % 4].set_title(title)\r\n",
    "#             ax[i // 4, i % 4].axis(\"off\")\r\n",
    "        \r\n",
    "#         plt.show()\r\n",
    "#         #plt.savefig(\"predictions_epoch_\"+ str(epoch)+'.png', bbox_inches = 'tight', pad_inches = 0)\r\n",
    "        \r\n",
    "#         figures_list.append(fig)\r\n",
    "\r\n",
    "#     def on_epoch_end(self, epoch, logs=None):\r\n",
    "#         if epoch % self.frequency == 0:\r\n",
    "#             self.plot_predictions(epoch) \r\n",
    "#             figures_list = []\r\n",
    "\r\n",
    "# class PlotPredictions(tf.keras.callbacks.Callback):\r\n",
    "\r\n",
    "#     def __init__(self, frequency=1):\r\n",
    "#         self.frequency = frequency\r\n",
    "#         super(PlotPredictions, self).__init__()\r\n",
    "\r\n",
    "#         batch = validation_dataset.take(1)\r\n",
    "#         self.batch_images = list(batch.as_numpy_iterator())[0][\"image\"]\r\n",
    "#         self.batch_labels = list(batch.as_numpy_iterator())[0][\"label\"]\r\n",
    "\r\n",
    "#     def plot_predictions(self, epoch):\r\n",
    "\r\n",
    "#         prediction_model = keras.models.Model(\r\n",
    "#             self.model.get_layer(name=\"image\").input, \r\n",
    "#             self.model.get_layer(name=\"dense\").output\r\n",
    "#         )\r\n",
    "        \r\n",
    "#         preds = prediction_model.predict(self.batch_images)\r\n",
    "#         pred_texts = ctc_decoder(preds)\r\n",
    "\r\n",
    "#         orig_texts = []\r\n",
    "\r\n",
    "#         for label in self.batch_labels:\r\n",
    "#             orig_texts.append(\"\".join([char_list[int(char_ind)] for char_ind in label if not(char_ind == len(char_list))]))\r\n",
    "\r\n",
    "#         fig , ax = plt.subplots(4, 4, figsize=(15, 5))\r\n",
    "#         fig.suptitle('Epoch: '+str(epoch), weight='bold', size=14)\r\n",
    "\r\n",
    "#         for i in range(16):\r\n",
    "\r\n",
    "#             img = (self.batch_images[i, :, :, 0] * 255).astype(np.uint8)\r\n",
    "#             title = f\"Prediction: {pred_texts[i]}\"\r\n",
    "#             ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\r\n",
    "#             ax[i // 4, i % 4].set_title(title)\r\n",
    "#             ax[i // 4, i % 4].axis(\"off\")\r\n",
    "        \r\n",
    "#         plt.show()\r\n",
    "#         #plt.savefig(\"predictions_epoch_\"+ str(epoch)+'.png', bbox_inches = 'tight', pad_inches = 0)\r\n",
    "        \r\n",
    "#         figures_list.append(fig)\r\n",
    "\r\n",
    "#     def on_epoch_end(self, epoch, logs=None):\r\n",
    "#         if epoch % self.frequency == 0:\r\n",
    "#             self.plot_predictions(epoch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "source": [
    "# def train(epochs):\r\n",
    "    \r\n",
    "#     # input with shape of height=32 and width=128 \r\n",
    "#     inputs = Input(shape=(32, 128, 1), name=\"image\", dtype=\"float32\")\r\n",
    "\r\n",
    "#     labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\r\n",
    "\r\n",
    "#     conv_1 = Conv2D(64, (3,3), activation = \"selu\", padding='same')(inputs)\r\n",
    "#     pool_1 = MaxPool2D(pool_size=(2, 2))(conv_1)\r\n",
    "    \r\n",
    "#     conv_2 = Conv2D(64, (3,3), activation = \"selu\", padding='same')(pool_1)\r\n",
    "#     pool_2 = MaxPool2D(pool_size=(2, 2))(conv_2)\r\n",
    "\r\n",
    "#     conv_3 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(pool_2)\r\n",
    "#     conv_4 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(conv_3)\r\n",
    "\r\n",
    "#     pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\r\n",
    "    \r\n",
    "#     conv_5 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(pool_4)\r\n",
    "    \r\n",
    "#     # Batch normalization layer\r\n",
    "#     batch_norm_5 = BatchNormalization()(conv_5)\r\n",
    "    \r\n",
    "#     conv_6 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(batch_norm_5)\r\n",
    "#     batch_norm_6 = BatchNormalization()(conv_6)\r\n",
    "#     pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\r\n",
    "    \r\n",
    "#     conv_7 = Conv2D(64, (2,2), activation = \"selu\")(pool_6)\r\n",
    "    \r\n",
    "#     squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\r\n",
    "    \r\n",
    "#     # bidirectional LSTM layers with units=128\r\n",
    "#     blstm_1 = Bidirectional(LSTM(128, return_sequences=True))(squeezed)\r\n",
    "#     blstm_2 = Bidirectional(LSTM(128, return_sequences=True))(blstm_1)\r\n",
    "\r\n",
    "#     softmax_output = Dense(len(char_list) + 1, activation = 'softmax', name=\"dense\")(blstm_2)\r\n",
    "\r\n",
    "#     output = CTCLayer(name=\"ctc_loss\")(labels, softmax_output)\r\n",
    "\r\n",
    "\r\n",
    "#     optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\r\n",
    "\r\n",
    "#     #model to be used at training time\r\n",
    "#     model = Model(inputs=[inputs, labels], outputs=output)\r\n",
    "#     model.compile(optimizer = optimizer)\r\n",
    "\r\n",
    "#     print(model.summary())\r\n",
    "#     file_path = \"C_LSTM_best.hdf5\"\r\n",
    "    \r\n",
    "#     checkpoint = ModelCheckpoint(filepath=file_path, \r\n",
    "#                                 monitor='val_loss', \r\n",
    "#                                 verbose=1, \r\n",
    "#                                 save_best_only=True, \r\n",
    "#                                 mode='min')\r\n",
    "\r\n",
    "#     callbacks_list = [checkpoint, \r\n",
    "#                       PlotPredictions(frequency=1),\r\n",
    "#                       EarlyStopping(patience=3, verbose=1)]\r\n",
    "\r\n",
    "#     history = model.fit(train_dataset, \r\n",
    "#                         epochs = epochs,\r\n",
    "#                         validation_data=validation_dataset,\r\n",
    "#                         verbose = 1,\r\n",
    "#                         callbacks = callbacks_list,\r\n",
    "#                         shuffle=True)\r\n",
    "    \r\n",
    "#     return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "source": [
    "# model = train(epochs=30)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "\r\n",
    "import keras\r\n",
    "from keras import backend as K\r\n",
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Reshape, Flatten, Dense\r\n",
    "from keras.layers import Bidirectional, LSTM, Lambda\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.optimizers import SGD\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "import math\r\n",
    "# char_list = set(['-', '.', '/',':','0','1','2','3','4','5','6','7','8',':','A','C','D','H','I','J','L','M','O','P','Q','R','T','V','a','b','c','d','e','f','g','h','i','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' '])\r\n",
    "char_list = set(['0','1','2','3','4','5','6','7','8',':','A','C','D','H','I','J','L','M','O','P','Q','R','T','V','a','b','c','d','e','f','g','h','i','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' '])\r\n",
    "\r\n",
    "\r\n",
    "window_height = 64  #windown height\r\n",
    "window_width = 64   #window width\r\n",
    "window_shift = window_width - 2 #window shift\r\n",
    "\r\n",
    "#CNN related configurations\r\n",
    "MPoolLayers_ALL = 4\t#Nbr of all maxpool layers\r\n",
    "MPoolLayers_H = 2\t#Nbr of maxpool in horizontal dimension\r\n",
    "LastFilters = 512\t#Nbr of feature maps at the last conv layer\r\n",
    "\r\n",
    "#LSTM related configurations\r\n",
    "NUnits = 256    #Number of units in forward/backward LSTM\r\n",
    "NLayers = 3     #Number of layers in BLSTM\r\n",
    "\r\n",
    "#%%\r\n",
    "FV = int(window_height / math.pow(2, MPoolLayers_ALL))\r\n",
    "# print(FV)\r\n",
    "NFeatures = FV * LastFilters\r\n",
    "\r\n",
    "#%%\r\n",
    "input_data = Input(shape=(window_height, window_width, 1), name=\"image\")\r\n",
    "# labels = layers.Input(name=\"label\", shape=(None,))\r\n",
    "labels = layers.Input(name=\"label\", shape=(None,))\r\n",
    "convolution1 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\")(input_data)\r\n",
    "convolution1 = BatchNormalization(axis = -1)(convolution1)\r\n",
    "\r\n",
    "convolution2 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\")(convolution1)\r\n",
    "convolution2 = BatchNormalization(axis = -1)(convolution2)\r\n",
    "\r\n",
    "pooling1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(convolution2)\r\n",
    "\r\n",
    "convolution3 = Conv2D(filters=128, kernel_size=(3,3),activation='relu', padding=\"same\")(pooling1)\r\n",
    "convolution3 = BatchNormalization(axis = -1)(convolution3)\r\n",
    "\r\n",
    "convolution4 = Conv2D(filters=128, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution3)\r\n",
    "convolution4 = BatchNormalization(axis = -1)(convolution4)\r\n",
    "\r\n",
    "pooling2 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(convolution4)\r\n",
    "\r\n",
    "convolution5 = Conv2D(filters=256, kernel_size=(3,3),activation='relu', padding=\"same\")(pooling2)\r\n",
    "convolution5 = BatchNormalization(axis = -1)(convolution5)\r\n",
    "\r\n",
    "convolution6 = Conv2D(filters=256, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution5)\r\n",
    "convolution6 = BatchNormalization(axis = -1)(convolution6)\r\n",
    "\r\n",
    "convolution7 = Conv2D(filters=256, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution6)\r\n",
    "convolution7 = BatchNormalization(axis = -1)(convolution7)\r\n",
    "\r\n",
    "pooling3 = MaxPooling2D(pool_size=(2,1), strides=(2,1),)(convolution7)\r\n",
    "\r\n",
    "convolution8 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(pooling3)\r\n",
    "convolution8 = BatchNormalization(axis = -1)(convolution8)\r\n",
    "\r\n",
    "convolution9 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution8)\r\n",
    "convolution9 = BatchNormalization(axis = -1)(convolution9)\r\n",
    "\r\n",
    "convolution10 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution9)\r\n",
    "convolution10= BatchNormalization(axis = -1)(convolution10)\r\n",
    "\r\n",
    "# pooling4 = MaxPooling2D(pool_size=(2,1), strides=(2,1))(convolution10)\r\n",
    "\r\n",
    "# convolution11 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(pooling4)\r\n",
    "# convolution11= BatchNormalization(axis = -1)(convolution11)\r\n",
    "\r\n",
    "# convolution12 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution11)\r\n",
    "# convolution12= BatchNormalization(axis = -1)(convolution12)\r\n",
    "\r\n",
    "# convolution13 = Conv2D(filters=512, kernel_size=(3,3),activation='relu', padding=\"same\")(convolution12)\r\n",
    "# convolution13= BatchNormalization(axis = -1)(convolution13)\r\n",
    "\r\n",
    "pooling5 = MaxPooling2D(pool_size=(2,1), strides=(2,1))(convolution10)\r\n",
    "# print(pooling5.shape)\r\n",
    "\r\n",
    "# new_shape = (None, (window_width // 32), (window_height // 32) * 512)\r\n",
    "# print(new_shape)\r\n",
    "# convolution_full = Reshape(target_shape=new_shape)(pooling5)\r\n",
    "convolution_full = Reshape(target_shape=(LastFilters * FV, 16))(pooling5)\r\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(convolution_full)\r\n",
    "x = layers.Dropout(0.2)(x)\r\n",
    "# flatten = Flatten()(pooling5)\r\n",
    "\r\n",
    "# convolution_full =Dense(512)(flatten)\r\n",
    "   \r\n",
    "    # bidirectional LSTM layers with units=128\r\n",
    "blstm_1 = Bidirectional(LSTM(256, return_sequences=True))(x)\r\n",
    "blstm_2 = Bidirectional(LSTM(256, return_sequences=True))(blstm_1)\r\n",
    "# blstm_3 = \r\n",
    "\r\n",
    "softmax_output = Dense(len(char_list) + 1, activation = 'softmax', name=\"dense\")(blstm_2)\r\n",
    "\r\n",
    "output = CTCLayer(name=\"ctc_loss\")(labels, softmax_output)\r\n",
    "\r\n",
    "\r\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\r\n",
    "\r\n",
    "    #model to be used at training time\r\n",
    "Model(inputs=[input_data, labels], outputs=output).summary()\r\n",
    "model = Model(inputs=[input_data, labels], outputs=output)\r\n",
    "model.compile(optimizer = optimizer)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 64, 64, 64)   640         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 64, 64, 64)   256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 64, 64, 64)   36928       batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 64, 64, 64)   256         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 32, 32, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 32, 32, 128)  73856       max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 128)  512         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 32, 32, 128)  147584      batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 128)  512         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 16, 16, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 256)  295168      max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 256)  1024        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 256)  590080      batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 256)  1024        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 256)  590080      batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 256)  1024        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 8, 16, 256)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 16, 512)   1180160     max_pooling2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 16, 512)   2048        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 16, 512)   2359808     batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 16, 512)   2048        conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 16, 512)   2359808     batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 16, 512)   2048        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 4, 16, 512)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 2048, 16)     0           max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 2048, 64)     1088        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048, 64)     0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 2048, 512)    657408      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 2048, 512)    1574912     bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048, 51)     26163       bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (CTCLayer)             (None, 2048, 51)     0           label[0][0]                      \n",
      "                                                                 dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 9,904,435\n",
      "Trainable params: 9,899,059\n",
      "Non-trainable params: 5,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# model.fit(train_dataset, \r\n",
    "#                         epochs = 1,\r\n",
    "#                         validation_data=validation_dataset,\r\n",
    "#                         verbose = 1,\r\n",
    "#                         shuffle=True)\r\n",
    "\r\n",
    "epochs = 1\r\n",
    "early_stopping_patience = 10\r\n",
    "# Add early stopping\r\n",
    "early_stopping = keras.callbacks.EarlyStopping(\r\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\r\n",
    ")\r\n",
    "\r\n",
    "# Train the model\r\n",
    "model.fit(\r\n",
    "    train_dataset,\r\n",
    "    validation_data=validation_dataset,\r\n",
    "    epochs=epochs,\r\n",
    "    callbacks=[early_stopping],\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#CNN TRIX"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#CNN CARL"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "6c0057e970611b3440242629919342879023e6b08fd2b04f89b50c3ebc2a3cfa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}