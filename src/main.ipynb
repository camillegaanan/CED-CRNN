{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jydsAcWgWVth"
      },
      "source": [
        "## 2 Google Drive Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3e7YJiXzSl"
      },
      "source": [
        "### 2.1 TensorFlow 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHw4tODULT1Z",
        "outputId": "e8915ae2-8580-437a-a42f-09be0ef101fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Nov 29 14:06:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMg-B5PH9h3r",
        "outputId": "639a636c-9db7-4bb0-bfb0-baf864193064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != \"/device:GPU:0\":\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMv5wyDXxqc"
      },
      "source": [
        "### 2.2 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACQn1iBF9k9O",
        "outputId": "fa66885c-ecec-47f9-b506-b3aaff75b877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at ./gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src\n",
            "total 848\n",
            "-rw------- 1 root root  45533 Nov 23 06:26 Battung_Dobutamine_3.png\n",
            "-rw------- 1 root root  33969 Nov 23 06:48 Battung_Tramadol_3.png\n",
            "-rw------- 1 root root  78605 Nov 23 06:46 Dangane_Rituximab_2.png\n",
            "-rw------- 1 root root  58370 Nov 23 06:13 Dasalla_Azathioprine_1.png\n",
            "drwx------ 2 root root   4096 Sep 27 12:47 data\n",
            "-rw------- 1 root root  38204 Nov 23 06:28 DeLosSantos_Hydroxyzine_1.png\n",
            "-rw------- 1 root root  20638 Nov 23 06:24 Ferraren_Chlorpromazine_2.png\n",
            "-rw------- 1 root root  53441 Nov 23 06:31 Lim_Lorazepam_1.png\n",
            "-rw------- 1 root root   9074 Sep 27 12:47 main.py\n",
            "-rw------- 1 root root     12 Oct 28 09:40 misclassified_words.csv\n",
            "drwx------ 2 root root   4096 Sep 27 12:47 network\n",
            "-rw------- 1 root root  44270 Nov 23 06:44 PayuranGatchalian_Risperidone_1.png\n",
            "-rw------- 1 root root  58354 Nov 23 07:54 predict.ipynb\n",
            "-rw------- 1 root root  35786 Nov 23 06:37 Ragab_Prednisolone_1.png\n",
            "-rw------- 1 root root  24975 Nov 23 06:33 Revecho_Metronidazole_2.png\n",
            "-rw------- 1 root root 231265 Nov 24 10:14 tutorial.ipynb\n",
            "-rw------- 1 root root  72953 Nov 23 06:21 Yenson_Ceftriaxone_1.png\n",
            "-rw------- 1 root root  50419 Nov 23 06:39 Yopo_Quinine_1.png\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"./gdrive\", force_remount=True)\n",
        "\n",
        "%cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwogUA8RZAyp"
      },
      "source": [
        "After mount, you can see the list os files in the project folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fj7fSngY1IX"
      },
      "source": [
        "## 3 Set Python Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Q4cOlWhNl3"
      },
      "source": [
        "### 3.1 Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qpr3drnGMWS",
        "outputId": "ba0c9225-ffa5-49e9-fe9e-638578b44938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source: ../data/doctors.hdf5\n",
            "output ../output/doctors/cnn_bilstm/simpler no noise ced with seed\n",
            "target ../output/doctors/cnn_bilstm/simpler no noise ced with seed/checkpoint_weights.hdf5\n",
            "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "import string\n",
        "\n",
        "# define parameters\n",
        "source = \"doctors\"\n",
        "arch = \"cnn_bilstm\"\n",
        "epochs = 200\n",
        "batch_size = 16\n",
        "\n",
        "# define paths\n",
        "source_path = os.path.join(\"..\", \"data\", f\"{source}.hdf5\")\n",
        "output_path = os.path.join(\"..\", \"output\", source, arch)\n",
        "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# define input size, number max of chars per line and list of valid chars\n",
        "input_size = (1024, 128, 1)\n",
        "max_text_length = 128\n",
        "charset_base = string.printable[:95]\n",
        "\n",
        "print(\"source:\", source_path)\n",
        "print(\"output\", output_path)\n",
        "print(\"target\", target_path)\n",
        "print(\"charset:\", charset_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFextshOhTKr"
      },
      "source": [
        "### 3.2 DataGenerator Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9vpNzMIAi2",
        "outputId": "39bac5ba-7828-4eb9-9266-7eff921a5853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 1848\n",
            "Validation images: 35\n",
            "Test images: 148\n"
          ]
        }
      ],
      "source": [
        "from data.generator import DataGenerator\n",
        "\n",
        "dtgen = DataGenerator(source=source_path,\n",
        "                      batch_size=batch_size,\n",
        "                      charset=charset_base,\n",
        "                      max_text_length=max_text_length)\n",
        "\n",
        "print(f\"Train images: {dtgen.size['train']}\")\n",
        "print(f\"Validation images: {dtgen.size['valid']}\")\n",
        "print(f\"Test images: {dtgen.size['test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OdgNLK0hYAA"
      },
      "source": [
        "### 3.3 HTRModel Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV0GreStISTR",
        "outputId": "bb77a351-dd7f-441c-b592-8832d6feb8b5"
      },
      "outputs": [],
      "source": [
        "from network.model import HTRModel\n",
        "\n",
        "# create and compile HTRModel\n",
        "model = HTRModel(architecture=arch,\n",
        "                 input_size=input_size,\n",
        "                 vocab_size=dtgen.tokenizer.vocab_size,\n",
        "                 beam_width=10,\n",
        "                 stop_tolerance=20,\n",
        "                 reduce_tolerance=15)\n",
        "\n",
        "model.compile(learning_rate=0.001, initial_step=0, target=\"model.jpg\", output=output_path,)\n",
        "model.summary(output_path, \"summary.txt\")\n",
        "\n",
        "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
        "model.load_checkpoint(target=target_path)\n",
        "\n",
        "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1fnz0Eugqru"
      },
      "source": [
        "## 4 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P6MSoxCISlD",
        "outputId": "5fb65403-1e0d-4d9f-a72d-e240388dfe93"
      },
      "outputs": [],
      "source": [
        "# to calculate total and average time per epoch\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "h = model.fit(x=dtgen.next_train_batch(),\n",
        "              epochs=epochs,\n",
        "              steps_per_epoch=dtgen.steps['train'],\n",
        "              validation_data=dtgen.next_valid_batch(),\n",
        "              validation_steps=dtgen.steps['valid'],\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True,\n",
        "              verbose=1)\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "loss = h.history['loss']\n",
        "val_loss = h.history['val_loss']\n",
        "\n",
        "min_val_loss = min(val_loss)\n",
        "min_val_loss_i = val_loss.index(min_val_loss)\n",
        "\n",
        "time_epoch = (total_time / len(loss))\n",
        "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
        "\n",
        "t_corpus = \"\\n\".join([\n",
        "    f\"Total train images:      {dtgen.size['train']}\",\n",
        "    f\"Total validation images: {dtgen.size['valid']}\",\n",
        "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
        "    f\"Total time:              {total_time}\",\n",
        "    f\"Time per epoch:          {time_epoch}\",\n",
        "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
        "    f\"Total epochs:            {len(loss)}\",\n",
        "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
        "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
        "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
        "    lg.write(t_corpus)\n",
        "    print(t_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13g7tDjWgtXV"
      },
      "source": [
        "## 5 Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddO26OT-g_QK"
      },
      "source": [
        "The predict process is similar to the *predict* of the Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a9iHL6tmaL_j",
        "outputId": "e4449c8c-fc69-4b31-95b3-eb4092a96a21"
      },
      "outputs": [],
      "source": [
        "from data import preproc as pp\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# predict() function will return the predicts with the probabilities\n",
        "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
        "                            steps=dtgen.steps['test'],\n",
        "                            ctc_decode=True,\n",
        "                            verbose=1)\n",
        "\n",
        "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
        "ground_truth = [x.decode() for x in dtgen.dataset['test']['gt']]\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "# mount predict corpus file\n",
        "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
        "    for pd, gt in zip(predicts, ground_truth,):\n",
        "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
        "   \n",
        "for i, item in enumerate(dtgen.dataset['test']['dt'][:5]):\n",
        "    print(\"=\" * 1024, \"\\n\")\n",
        "    cv2_imshow(pp.adjust_to_see(item))\n",
        "    print(ground_truth[i])\n",
        "    print(predicts[i], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcAs3Q3WNJ-"
      },
      "source": [
        "## 6 Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LuZBRepWbom"
      },
      "source": [
        "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
        "\n",
        "* predicts\n",
        "* ground_truth\n",
        "* norm_accentuation (calculation with/without accentuation)\n",
        "* norm_punctuation (calculation with/without punctuation marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gCwEYdKWOPK",
        "outputId": "554f5905-3bf9-4996-e8bf-13639790bd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyastronomy\n",
            "  Downloading PyAstronomy-0.17.0.tar.gz (727 kB)\n",
            "\u001b[K     |████████████████████████████████| 727 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyastronomy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyastronomy) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyastronomy) (1.4.1)\n",
            "Collecting quantities\n",
            "  Downloading quantities-0.12.5.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting bidict\n",
            "  Downloading bidict-0.21.4-py3-none-any.whl (36 kB)\n",
            "Building wheels for collected packages: pyastronomy, quantities\n",
            "  Building wheel for pyastronomy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyastronomy: filename=PyAstronomy-0.17.0-py3-none-any.whl size=522050 sha256=737e7313ec77c0c7b3ffd8b3075ed705a81b986e196a023f252172e6fc96649f\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/f4/cc/fe117c538c81443a6ba0e852ee8d69866a08e5163d2050aae5\n",
            "  Building wheel for quantities (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quantities: filename=quantities-0.12.5-py3-none-any.whl size=80135 sha256=a4ef256e2dea67267b8a6bfad1b7eb7645c35bd5a78c36d7b55066b4a8e160df\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/e7/32/0bb6d5bd0f619e583b6f1f4c710b535df898a1083e1e5d066c\n",
            "Successfully built pyastronomy quantities\n",
            "Installing collected packages: quantities, bidict, pyastronomy\n",
            "Successfully installed bidict-0.21.4 pyastronomy-0.17.0 quantities-0.12.5\n",
            "Total test images:    148\n",
            "Total time:           0:00:29.457390\n",
            "Time per item:        0:00:00.199036\n",
            "\n",
            "Metrics:\n",
            "Character Error Rate:       0.05433013\n",
            "Word Error Rate:            0.09772045\n",
            "f1-score:                   72.29729730\n",
            "Recall:                     89.97050147\n",
            "Precision:                  90.05905512\n",
            "F1 score:                   90.01475652\n",
            "CER: [0.0, 0.0, 0.0, 0.0, 0.02040816326530612, 0.0, 0.6122448979591837, 0.0, 0.0, 0.12244897959183673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06060606060606061, 0.061224489795918366, 0.0, 0.030303030303030304, 0.2777777777777778, 0.0, 0.0, 0.06060606060606061, 0.0, 0.0, 0.0, 0.0, 0.02040816326530612, 0.0, 0.0, 0.0, 0.0, 0.03571428571428571, 0.3793103448275862, 0.0, 0.041666666666666664, 0.0, 0.7291666666666666, 0.0, 0.020833333333333332, 0.0, 0.034482758620689655, 0.0, 0.0, 0.0, 0.38235294117647056, 0.0, 0.35294117647058826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06060606060606061, 0.0, 0.56, 0.02040816326530612, 0.02857142857142857, 0.20408163265306123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020833333333333332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 0.02040816326530612, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.1111111111111111, 0.1875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020833333333333332, 0.0, 0.06060606060606061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.775, 0.0, 0.0, 0.02040816326530612, 0.0, 0.04081632653061224, 0.0, 0.027777777777777776, 0.0, 0.0, 0.0, 0.0, 0.5277777777777778, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.02040816326530612, 0.0, 0.0, 0.30303030303030304, 0.0, 0.23529411764705882, 0.0, 0.0, 0.10204081632653061]\n",
            "azathioprine accuracy:      8\n",
            "ceftriaxone accuracy:       11\n",
            "chlorpromazine accuracy:    0\n",
            "dobutamine accuracy:        11\n",
            "hydroxyzine accuracy:       9\n",
            "lorazepam accuracy:         9\n",
            "metronidazole accuracy:     11\n",
            "prednisolone accuracy:      7\n",
            "quinine accuracy:           13\n",
            "risperidone accuracy:       11\n",
            "rituximab accuracy:         10\n",
            "tramadol accuracy:          7\n",
            "azathioprine recall:      79.72972972972973\n",
            "ceftriaxone recall:       98.33333333333333\n",
            "chlorpromazine recall:    79.24528301886792\n",
            "dobutamine recall:        89.1891891891892\n",
            "hydroxyzine recall:       83.33333333333334\n",
            "lorazepam recall:         91.42857142857143\n",
            "metronidazole recall:     97.43589743589743\n",
            "prednisolone recall:      93.05555555555556\n",
            "quinine recall:           100.0\n",
            "risperidone recall:       96.92307692307692\n",
            "rituximab recall:         89.04109589041096\n",
            "tramadol recall:          83.33333333333334\n",
            "azathioprine precision:      81.94444444444444\n",
            "ceftriaxone precision:       98.33333333333333\n",
            "chlorpromazine precision:    77.77777777777779\n",
            "dobutamine precision:        91.66666666666666\n",
            "hydroxyzine precision:       83.33333333333334\n",
            "lorazepam precision:         88.88888888888889\n",
            "metronidazole precision:     97.43589743589743\n",
            "prednisolone precision:      93.05555555555556\n",
            "quinine precision:           100.0\n",
            "risperidone precision:       96.92307692307692\n",
            "rituximab precision:         90.27777777777779\n",
            "tramadol precision:          84.61538461538461\n",
            "azathioprine f1-score:      80.82191780821917\n",
            "ceftriaxone f1-score:       98.33333333333333\n",
            "chlorpromazine f1-score:    78.50467289719626\n",
            "dobutamine f1-score:        90.41095890410958\n",
            "hydroxyzine f1-score:       83.33333333333334\n",
            "lorazepam f1-score:         90.14084507042254\n",
            "metronidazole f1-score:     97.43589743589743\n",
            "prednisolone f1-score:      93.05555555555556\n",
            "quinine f1-score:           100.0\n",
            "risperidone f1-score:       96.92307692307692\n",
            "rituximab f1-score:         89.65517241379311\n",
            "tramadol f1-score:          83.96946564885496\n",
            "azathioprine CER:      0.15111036838978015\n",
            "ceftriaxone CER:       0.006666666666666667\n",
            "chlorpromazine CER:    0.1054421768707483\n",
            "dobutamine CER:        0.03160919540229885\n",
            "hydroxyzine CER:       0.08068738859180036\n",
            "lorazepam CER:         0.06944444444444445\n",
            "metronidazole CER:     0.017094017094017092\n",
            "prednisolone CER:      0.022727272727272724\n",
            "quinine CER:           0.0\n",
            "risperidone CER:       0.005399772641151952\n",
            "rituximab CER:         0.06190476190476191\n",
            "tramadol CER:          0.10717948717948717\n",
            "azathioprine WER:      0.1898148148148148\n",
            "ceftriaxone WER:       0.016666666666666666\n",
            "chlorpromazine WER:    0.2222222222222223\n",
            "dobutamine WER:        0.08333333333333333\n",
            "hydroxyzine WER:       0.16666666666666666\n",
            "lorazepam WER:         0.1111111111111111\n",
            "metronidazole WER:     0.02564102564102564\n",
            "prednisolone WER:      0.06944444444444443\n",
            "quinine WER:           0.0\n",
            "risperidone WER:       0.03076923076923077\n",
            "rituximab WER:         0.09722222222222222\n",
            "tramadol WER:          0.17319347319347322\n"
          ]
        }
      ],
      "source": [
        "pip install pyastronomy\n",
        "from data import evaluation\n",
        "\n",
        "cer, evaluate, acc, labels = evaluation.ocr_metrics(predicts, ground_truth, output_path)\n",
        "\n",
        "e_corpus = \"\\n\".join([\n",
        "    f\"Total test images:    {dtgen.size['test']}\",\n",
        "    f\"Total time:           {total_time}\",\n",
        "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
        "    f\"Metrics:\",\n",
        "    f\"Character Error Rate:       {evaluate[0]:.8f}\",\n",
        "    f\"Word Error Rate:            {evaluate[1]:.8f}\",\n",
        "    f\"f1-score:                   {evaluate[2]:.8f}\",\n",
        "    f\"Recall:                     {evaluate[3]:.8f}\",\n",
        "    f\"Precision:                  {evaluate[4]:.8f}\",\n",
        "    f\"F1 score:                   {evaluate[5]:.8f}\",\n",
        "    f\"CER: {cer}\",\n",
        "    f\"azathioprine accuracy:      {acc[0]}\",\n",
        "    f\"ceftriaxone accuracy:       {acc[1]}\",\n",
        "    f\"chlorpromazine accuracy:    {acc[2]}\",\n",
        "    f\"dobutamine accuracy:        {acc[3]}\",\n",
        "    f\"hydroxyzine accuracy:       {acc[4]}\",\n",
        "    f\"lorazepam accuracy:         {acc[5]}\",\n",
        "    f\"metronidazole accuracy:     {acc[6]}\",\n",
        "    f\"prednisolone accuracy:      {acc[7]}\",\n",
        "    f\"quinine accuracy:           {acc[8]}\",\n",
        "    f\"risperidone accuracy:       {acc[9]}\",\n",
        "    f\"rituximab accuracy:         {acc[10]}\",\n",
        "    f\"tramadol accuracy:          {acc[11]}\",\n",
        "    f\"azathioprine recall:      {labels[0][0]}\",\n",
        "    f\"ceftriaxone recall:       {labels[0][1]}\",\n",
        "    f\"chlorpromazine recall:    {labels[0][2]}\",\n",
        "    f\"dobutamine recall:        {labels[0][3]}\",\n",
        "    f\"hydroxyzine recall:       {labels[0][4]}\",\n",
        "    f\"lorazepam recall:         {labels[0][5]}\",\n",
        "    f\"metronidazole recall:     {labels[0][6]}\",\n",
        "    f\"prednisolone recall:      {labels[0][7]}\",\n",
        "    f\"quinine recall:           {labels[0][8]}\",\n",
        "    f\"risperidone recall:       {labels[0][9]}\",\n",
        "    f\"rituximab recall:         {labels[0][10]}\",\n",
        "    f\"tramadol recall:          {labels[0][11]}\",\n",
        "    f\"azathioprine precision:      {labels[1][0]}\",\n",
        "    f\"ceftriaxone precision:       {labels[1][1]}\",\n",
        "    f\"chlorpromazine precision:    {labels[1][2]}\",\n",
        "    f\"dobutamine precision:        {labels[1][3]}\",\n",
        "    f\"hydroxyzine precision:       {labels[1][4]}\",\n",
        "    f\"lorazepam precision:         {labels[1][5]}\",\n",
        "    f\"metronidazole precision:     {labels[1][6]}\",\n",
        "    f\"prednisolone precision:      {labels[1][7]}\",\n",
        "    f\"quinine precision:           {labels[1][8]}\",\n",
        "    f\"risperidone precision:       {labels[1][9]}\",\n",
        "    f\"rituximab precision:         {labels[1][10]}\",\n",
        "    f\"tramadol precision:          {labels[1][11]}\",\n",
        "    f\"azathioprine f1-score:      {labels[2][0]}\",\n",
        "    f\"ceftriaxone f1-score:       {labels[2][1]}\",\n",
        "    f\"chlorpromazine f1-score:    {labels[2][2]}\",\n",
        "    f\"dobutamine f1-score:        {labels[2][3]}\",\n",
        "    f\"hydroxyzine f1-score:       {labels[2][4]}\",\n",
        "    f\"lorazepam f1-score:         {labels[2][5]}\",\n",
        "    f\"metronidazole f1-score:     {labels[2][6]}\",\n",
        "    f\"prednisolone f1-score:      {labels[2][7]}\",\n",
        "    f\"quinine f1-score:           {labels[2][8]}\",\n",
        "    f\"risperidone f1-score:       {labels[2][9]}\",\n",
        "    f\"rituximab f1-score:         {labels[2][10]}\",\n",
        "    f\"tramadol f1-score:          {labels[2][11]}\",\n",
        "    f\"azathioprine CER:      {labels[3][0]}\",\n",
        "    f\"ceftriaxone CER:       {labels[3][1]}\",\n",
        "    f\"chlorpromazine CER:    {labels[3][2]}\",\n",
        "    f\"dobutamine CER:        {labels[3][3]}\",\n",
        "    f\"hydroxyzine CER:       {labels[3][4]}\",\n",
        "    f\"lorazepam CER:         {labels[3][5]}\",\n",
        "    f\"metronidazole CER:     {labels[3][6]}\",\n",
        "    f\"prednisolone CER:      {labels[3][7]}\",\n",
        "    f\"quinine CER:           {labels[3][8]}\",\n",
        "    f\"risperidone CER:       {labels[3][9]}\",\n",
        "    f\"rituximab CER:         {labels[3][10]}\",\n",
        "    f\"tramadol CER:          {labels[3][11]}\",\n",
        "    f\"azathioprine WER:      {labels[4][0]}\",\n",
        "    f\"ceftriaxone WER:       {labels[4][1]}\",\n",
        "    f\"chlorpromazine WER:    {labels[4][2]}\",\n",
        "    f\"dobutamine WER:        {labels[4][3]}\",\n",
        "    f\"hydroxyzine WER:       {labels[4][4]}\",\n",
        "    f\"lorazepam WER:         {labels[4][5]}\",\n",
        "    f\"metronidazole WER:     {labels[4][6]}\",\n",
        "    f\"prednisolone WER:      {labels[4][7]}\",\n",
        "    f\"quinine WER:           {labels[4][8]}\",\n",
        "    f\"risperidone WER:       {labels[4][9]}\",\n",
        "    f\"rituximab WER:         {labels[4][10]}\",\n",
        "    f\"tramadol WER:          {labels[4][11]}\",\n",
        "])\n",
        "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
        "    lg.write(e_corpus)\n",
        "    print(e_corpus)\n",
        "\n",
        "evaluation.statistical_test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tutorial.ipynb",
      "provenance": []
    },
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
